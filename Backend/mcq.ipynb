{
 "cells": [
  {
   "cell_type": "code",
   "id": "9ab515bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T11:14:03.634539Z",
     "start_time": "2025-10-05T11:14:03.629989Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pygame.examples.video import answer\n",
    "from reportlab.lib.randomtext import subjects\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense,Dropout\n",
    "import spacy\n",
    "import random\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "id": "0022a3bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T11:14:05.452512Z",
     "start_time": "2025-10-05T11:14:05.077610Z"
    }
   },
   "source": "nlp = spacy.load(\"en_core_web_sm\")",
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "id": "500656a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T11:14:06.033158Z",
     "start_time": "2025-10-05T11:14:06.021295Z"
    }
   },
   "source": [
    "doc = nlp(\"Apple is looking at buying a startup in the United States.\")\n",
    "doc"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apple is looking at buying a startup in the United States."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T11:14:06.599928Z",
     "start_time": "2025-10-05T11:14:06.594708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_text(text):\n",
    "    doc=nlp(text)\n",
    "    sentence=[sent.text for sent in doc.sents]\n",
    "    return sentence\n",
    "\n",
    "def create_training_data(sentence,tokenizer,max_length):\n",
    "    sentence=tokenizer.texts_to_sequences(sentence)\n",
    "    padded_sequences=pad_sequences(sentence,maxlen=max_length,padding='post')\n",
    "    return padded_sequences\n",
    "\n",
    "\n",
    "\n",
    "def build_lstm_model(vocab_size, max_length, embedding_dim):\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "        LSTM(128, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(64),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(vocab_size, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n"
   ],
   "id": "ae89429b17476b47",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T11:14:07.034967Z",
     "start_time": "2025-10-05T11:14:07.029135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_similar_words(word, num_similar=3):\n",
    "    word_token = nlp.vocab[word] if word in nlp.vocab else None\n",
    "    if not word_token or not word_token.has_vector:\n",
    "        return [\"[Distractor]\"] * num_similar  # Return placeholders if no vector is found\n",
    "\n",
    "    # Compute similarity with other words in vocab\n",
    "    similarities = []\n",
    "    for token in nlp.vocab:\n",
    "        if token.is_alpha and token.has_vector and token != word_token:\n",
    "            similarity = word_token.similarity(token)\n",
    "            similarities.append((token.text, similarity))\n",
    "\n",
    "    # Sort and return top similar words\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [word for word, _ in similarities[:num_similar]]"
   ],
   "id": "ef4739207e0099f4",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T11:14:07.409003Z",
     "start_time": "2025-10-05T11:14:07.402899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_mcqs_lstm(text, tokenizer, max_length, model, num_questions=5):\n",
    "    sentences = preprocess_text(text)\n",
    "    selected_sentences = random.sample(sentences, min(num_questions, len(sentences)))\n",
    "\n",
    "    mcqs = []\n",
    "    for sentence in selected_sentences:\n",
    "        doc = nlp(sentence)\n",
    "        nouns = [token.text for token in doc if token.pos_ == \"NOUN\"]\n",
    "        if len(nouns) < 1:\n",
    "            continue\n",
    "\n",
    "        subject = random.choice(nouns)\n",
    "        question_stem = sentence.replace(subject, \"______\")\n",
    "\n",
    "        # Generate similar words using spaCy\n",
    "        similar_words = find_similar_words(subject, num_similar=3)\n",
    "\n",
    "        answer_choices = [subject] + similar_words\n",
    "        random.shuffle(answer_choices)\n",
    "        correct_answer = chr(65 + answer_choices.index(subject))\n",
    "\n",
    "        mcqs.append((question_stem, answer_choices, correct_answer))\n",
    "\n",
    "    return mcqs"
   ],
   "id": "13aea8ce8ff4cd3f",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T11:14:07.776195Z",
     "start_time": "2025-10-05T11:14:07.771931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"\"\"Deep learning is a subset of machine learning that uses neural networks. LSTMs are useful for processing sequential data like text.\n",
    "Natural language processing involves techniques like tokenization and named entity recognition.\"\"\"\n"
   ],
   "id": "6f6a0bb19f828633",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T11:14:08.227671Z",
     "start_time": "2025-10-05T11:14:08.173452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(preprocess_text(text))\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_length = 20\n",
    "\n",
    "# Train LSTM model (Note: Training requires large datasets)\n",
    "model = build_lstm_model(vocab_size, max_length, embedding_dim=100)\n",
    "\n",
    "# Generate MCQs\n",
    "mcqs = generate_mcqs_lstm(text, tokenizer, max_length, model, num_questions=3)\n",
    "for i, (q, choices, ans) in enumerate(mcqs, 1):\n",
    "    print(f\"Q{i}: {q}\")\n",
    "    print(f\" A) {choices[0]}  B) {choices[1]}  C) {choices[2]}  D) {choices[3]}\")\n",
    "    print(f\"Correct Answer: {ans}\\n\")"
   ],
   "id": "9e00b27c15cc4099",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: Natural language ______ involves techniques like tokenization and named entity recognition.\n",
      " A) processing  B) [Distractor]  C) [Distractor]  D) [Distractor]\n",
      "Correct Answer: A\n",
      "\n",
      "Q2: Deep ______ is a subset of machine ______ that uses neural networks.\n",
      " A) [Distractor]  B) [Distractor]  C) [Distractor]  D) learning\n",
      "Correct Answer: D\n",
      "\n",
      "Q3: LSTMs are useful for processing sequential ______ like text.\n",
      "\n",
      " A) data  B) [Distractor]  C) [Distractor]  D) [Distractor]\n",
      "Correct Answer: A\n",
      "\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:45:28.446805Z",
     "start_time": "2025-10-05T13:39:36.395540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_id = \"voidful/bart-eqg-question-generator\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "\n",
    "context = \"\"\"Mitosis is a part of the cell cycle in which replicated chromosomes are separated into two new nuclei.\"\"\"\n",
    "prompt = f\"Generate 3 multiple choice questions from this paragraph:\\n{context}\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=256)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ],
   "id": "43d8c23c78cd554e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:  84%|########3 | 598M/712M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d732da9a64194133bcf56df68603abd9"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at voidful/bart-eqg-question-generator and are newly initialized: ['model.decoder.embed_tokens.weight', 'model.encoder.embed_tokens.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who who is is is will is wentc ( is .a ( .a\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:45:32.207643Z",
     "start_time": "2025-10-05T13:45:28.504128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.save_pretrained(\"my_mcq_model\")\n",
    "tokenizer.save_pretrained(\"my_mcq_model\")\n"
   ],
   "id": "863e3985bf9c9926",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vansh\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:3917: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('my_mcq_model\\\\tokenizer_config.json',\n",
       " 'my_mcq_model\\\\special_tokens_map.json',\n",
       " 'my_mcq_model\\\\vocab.json',\n",
       " 'my_mcq_model\\\\merges.txt',\n",
       " 'my_mcq_model\\\\added_tokens.json',\n",
       " 'my_mcq_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T13:49:03.208320Z",
     "start_time": "2025-10-05T13:48:54.695796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context = \"\"\"\n",
    "Photosynthesis is the process by which green plants, algae, and certain bacteria convert light energy into chemical energy stored in glucose.\n",
    "This process mainly takes place in the chloroplasts of plant cells, which contain the green pigment chlorophyll that captures light energy.\n",
    "Photosynthesis occurs in two main stages: the light-dependent reactions and the light-independent reactions (Calvin cycle).\n",
    "During the light-dependent reactions, sunlight is absorbed by chlorophyll, and the energy is used to split water molecules into oxygen, protons, and electrons.\n",
    "Oxygen is released as a byproduct, while ATP and NADPH are produced as energy carriers.\n",
    "In the Calvin cycle, which takes place in the stroma of the chloroplast, ATP and NADPH are used to fix carbon dioxide into glucose.\n",
    "This glucose provides energy for the plant’s growth, reproduction, and other metabolic activities.\n",
    "Photosynthesis is crucial for life on Earth as it not only provides oxygen but also serves as the foundation of the food chain.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Generate questions from this paragraph:\\n{context}\"\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=256,\n",
    "    temperature=0.8,\n",
    "    top_p=0.9,\n",
    "    top_k=50,\n",
    "    repetition_penalty=1.2,\n",
    "    no_repeat_ngram_size=3\n",
    ")\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=256)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ],
   "id": "5e46496c8ee228bf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who whoier is is is wasku to , to ( to to ( ( ( isa ( ) ( ( .a ( ( ) . ( ( a ( ( overaya ( . a\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1c22c4c66e9d62a5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
